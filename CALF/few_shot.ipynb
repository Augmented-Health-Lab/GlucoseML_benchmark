{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qy0D1AShIRq-","executionInfo":{"status":"ok","timestamp":1769539537175,"user_tz":300,"elapsed":663,"user":{"displayName":"PI DigitalSMD","userId":"16790990030515584217"}},"outputId":"bf3607d1-5f99-4bb9-96eb-d966b4d0298a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Working directory: /content/drive/Shareddrives/Baiying\n","/content/drive/Shareddrives/Baiying/CALF\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","shared_path = '/content/drive/Shareddrives/Baiying'\n","os.chdir(shared_path)\n","print(\"Working directory:\", os.getcwd())\n","\n","%cd CALF"]},{"cell_type":"code","source":["!pip install -r new_requirement.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"ZT2SA8EfIXL0","executionInfo":{"status":"ok","timestamp":1769539376659,"user_tz":300,"elapsed":29446,"user":{"displayName":"PI DigitalSMD","userId":"16790990030515584217"}},"outputId":"bd02ecfd-6970-4a2e-9775-874e6dfedeab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting absl-py==1.2.0 (from -r new_requirement.txt (line 1))\n","  Downloading absl_py-1.2.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting einops==0.4.1 (from -r new_requirement.txt (line 2))\n","  Downloading einops-0.4.1-py3-none-any.whl.metadata (10 kB)\n","Collecting opt-einsum==3.3.0 (from -r new_requirement.txt (line 3))\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Collecting patool==1.15.0 (from -r new_requirement.txt (line 4))\n","  Downloading patool-1.15.0-py2.py3-none-any.whl.metadata (3.8 kB)\n","Collecting PyWavelets==1.5.0 (from -r new_requirement.txt (line 6))\n","  Downloading pywavelets-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Collecting pytorch-wavelet==1.2 (from -r new_requirement.txt (line 7))\n","  Downloading pytorch_wavelet-1.2-py3-none-any.whl.metadata (852 bytes)\n","Collecting scikit-image==0.22.0 (from -r new_requirement.txt (line 9))\n","  Downloading scikit_image-0.22.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Collecting statsmodels==0.14.1 (from -r new_requirement.txt (line 10))\n","  Downloading statsmodels-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n","Collecting keopscore==2.1 (from -r new_requirement.txt (line 11))\n","  Downloading keopscore-2.1.tar.gz (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting transformers==4.38.2 (from -r new_requirement.txt (line 13))\n","  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting peft==0.9.0 (from -r new_requirement.txt (line 14))\n","  Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.12/dist-packages (from opt-einsum==3.3.0->-r new_requirement.txt (line 3)) (2.0.2)\n","Collecting numpy>=1.7 (from opt-einsum==3.3.0->-r new_requirement.txt (line 3))\n","  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (2.9.0+cu126)\n","Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.22.0->-r new_requirement.txt (line 9)) (1.16.3)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.22.0->-r new_requirement.txt (line 9)) (3.6.1)\n","Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.22.0->-r new_requirement.txt (line 9)) (11.3.0)\n","Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.22.0->-r new_requirement.txt (line 9)) (2.37.2)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.22.0->-r new_requirement.txt (line 9)) (2026.1.14)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.22.0->-r new_requirement.txt (line 9)) (25.0)\n","Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from scikit-image==0.22.0->-r new_requirement.txt (line 9)) (0.4)\n","Requirement already satisfied: pandas!=2.1.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from statsmodels==0.14.1->-r new_requirement.txt (line 10)) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.12/dist-packages (from statsmodels==0.14.1->-r new_requirement.txt (line 10)) (1.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->-r new_requirement.txt (line 13)) (3.20.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->-r new_requirement.txt (line 13)) (0.36.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->-r new_requirement.txt (line 13)) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->-r new_requirement.txt (line 13)) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->-r new_requirement.txt (line 13)) (2.32.4)\n","Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2->-r new_requirement.txt (line 13))\n","  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->-r new_requirement.txt (line 13)) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2->-r new_requirement.txt (line 13)) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.9.0->-r new_requirement.txt (line 14)) (5.9.5)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.9.0->-r new_requirement.txt (line 14)) (1.12.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->-r new_requirement.txt (line 13)) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->-r new_requirement.txt (line 13)) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->-r new_requirement.txt (line 13)) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.1.0,>=1.0->statsmodels==0.14.1->-r new_requirement.txt (line 10)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.1.0,>=1.0->statsmodels==0.14.1->-r new_requirement.txt (line 10)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.1.0,>=1.0->statsmodels==0.14.1->-r new_requirement.txt (line 10)) (2025.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (1.14.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (3.5.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2->-r new_requirement.txt (line 13)) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2->-r new_requirement.txt (line 13)) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2->-r new_requirement.txt (line 13)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2->-r new_requirement.txt (line 13)) (2026.1.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.0->statsmodels==0.14.1->-r new_requirement.txt (line 10)) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.0->pytorch-wavelet==1.2->-r new_requirement.txt (line 7)) (3.0.3)\n","Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading einops-0.4.1-py3-none-any.whl (28 kB)\n","Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading patool-1.15.0-py2.py3-none-any.whl (91 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pywavelets-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_wavelet-1.2-py3-none-any.whl (2.8 kB)\n","Downloading scikit_image-0.22.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading statsmodels-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.9.0-py3-none-any.whl (190 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: keopscore\n","  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keopscore: filename=keopscore-2.1-py3-none-any.whl size=147451 sha256=21028b4a5bd02820fd08dac88dc7c2a4ea0d112fa5accf764528c8622ba3b241\n","  Stored in directory: /root/.cache/pip/wheels/d8/c6/cc/e8b5e1ba507120e9fe86937986ce9333078720fb6c0046870d\n","Successfully built keopscore\n","Installing collected packages: einops, patool, numpy, keopscore, absl-py, PyWavelets, opt-einsum, tokenizers, statsmodels, scikit-image, transformers, pytorch-wavelet, peft\n","  Attempting uninstall: einops\n","    Found existing installation: einops 0.8.1\n","    Uninstalling einops-0.8.1:\n","      Successfully uninstalled einops-0.8.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.4.0\n","    Uninstalling absl-py-1.4.0:\n","      Successfully uninstalled absl-py-1.4.0\n","  Attempting uninstall: PyWavelets\n","    Found existing installation: PyWavelets 1.9.0\n","    Uninstalling PyWavelets-1.9.0:\n","      Successfully uninstalled PyWavelets-1.9.0\n","  Attempting uninstall: opt-einsum\n","    Found existing installation: opt_einsum 3.4.0\n","    Uninstalling opt_einsum-3.4.0:\n","      Successfully uninstalled opt_einsum-3.4.0\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.2\n","    Uninstalling tokenizers-0.22.2:\n","      Successfully uninstalled tokenizers-0.22.2\n","  Attempting uninstall: statsmodels\n","    Found existing installation: statsmodels 0.14.6\n","    Uninstalling statsmodels-0.14.6:\n","      Successfully uninstalled statsmodels-0.14.6\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.25.2\n","    Uninstalling scikit-image-0.25.2:\n","      Successfully uninstalled scikit-image-0.25.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.57.6\n","    Uninstalling transformers-4.57.6:\n","      Successfully uninstalled transformers-4.57.6\n","  Attempting uninstall: peft\n","    Found existing installation: peft 0.18.1\n","    Uninstalling peft-0.18.1:\n","      Successfully uninstalled peft-0.18.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","sentence-transformers 5.2.0 requires transformers<6.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed PyWavelets-1.5.0 absl-py-1.2.0 einops-0.4.1 keopscore-2.1 numpy-1.26.4 opt-einsum-3.3.0 patool-1.15.0 peft-0.9.0 pytorch-wavelet-1.2 scikit-image-0.22.0 statsmodels-0.14.1 tokenizers-0.15.2 transformers-4.38.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"86c5a636fcd3415aa21c317381b5abef"}},"metadata":{}}]},{"cell_type":"code","source":["!python run.py \\\n","  --task_name long_term_forecast \\\n","  --is_training 1 \\\n","  --model CALF \\\n","  --model_id glucose_train_few_shot \\\n","  --data Glucose \\\n","  --root_path /content/drive/Shareddrives/Baiying/preprocessed_dataset/training_dataset/mixed \\\n","  --features S \\\n","  --target BGvalue \\\n","  --freq 5min \\\n","  --d_model 768 \\\n","  --n_heads 12 \\\n","  --seq_len 144 \\\n","  --label_len 72 \\\n","  --pred_len 18 \\\n","  --enc_in 1 \\\n","  --dec_in 1 \\\n","  --c_out 1 \\\n","  --stride 1 \\\n","  --batch_size 8 \\\n","  --gpt_layers 4 \\\n","  --train_epochs 30 \\\n","  --patience 8 \\\n","  --stride 240 \\\n","  --learning_rate 1e-4 \\\n","  --scale_value 1.0 \\\n","  --max_windows_per_epoch 30000 \\\n","  --num_workers 2 \\\n","  --use_gpu 1 \\\n","  --per_subject_eval 0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"C3zU70s7IXN3","executionInfo":{"status":"ok","timestamp":1768792607033,"user_tz":300,"elapsed":1074103,"user":{"displayName":"PI DigitalSMD","userId":"16790990030515584217"}},"outputId":"ba1ef440-b463-437b-9e4a-51e1972e3e1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Args in experiment:\n","\u001b[1mBasic Config\u001b[0m\n","  Task Name:          long_term_forecast  Is Training:        1                   \n","  Model ID:           glucose_train_few_shotModel:              CALF                \n","\n","\u001b[1mData Loader\u001b[0m\n","  Data:               Glucose             Root Path:          /content/drive/Shareddrives/Baiying/preprocessed_dataset/training_dataset/mixed\n","  Data Path:          ETTh1.csv           Features:           S                   \n","  Target:             BGvalue             Freq:               5min                \n","  Checkpoints:        ./checkpoints/      \n","\n","\u001b[1mForecasting Task\u001b[0m\n","  Seq Len:            144                 Label Len:          72                  \n","  Pred Len:           18                  Seasonal Patterns:  Monthly             \n","  Inverse:            0                   \n","\n","\u001b[1mModel Parameters\u001b[0m\n","  Top k:              5                   Num Kernels:        6                   \n","  Enc In:             1                   Dec In:             1                   \n","  C Out:              1                   d model:            768                 \n","  n heads:            12                  e layers:           2                   \n","  d layers:           1                   d FF:               2048                \n","  Moving Avg:         25                  Factor:             1                   \n","  Distil:             1                   Dropout:            0.1                 \n","  Embed:              timeF               Activation:         gelu                \n","  Output Attention:   0                   \n","\n","\u001b[1mRun Parameters\u001b[0m\n","  Num Workers:        2                   Itr:                1                   \n","  Train Epochs:       30                  Batch Size:         8                   \n","  Patience:           8                   Learning Rate:      0.0001              \n","  Des:                test                Feature Loss:       l1                  Output Loss:        l1                  Task Loss:          l1                  \n","  Lradj:              type1               Use Amp:            0                   \n","\n","\u001b[1mGPU\u001b[0m\n","  Use GPU:            1                   GPU:                0                   \n","  Use Multi GPU:      0                   Devices:            0,1,2,3             \n","\n","\u001b[1mDe-stationary Projector Params\u001b[0m\n","  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n","\n","\u001b[1mDistill Loss Weight\u001b[0m\n","  Feature Weight:     0.01                Output Weight:      1.0                 Task Weight:        1.0                 \n","\n","Use GPU: cuda:0\n","config.json: 100% 665/665 [00:00<00:00, 4.40MB/s]\n","model.safetensors: 100% 548M/548M [00:02<00:00, 222MB/s]\n",">>>>>>>start training : long_term_forecast_glucose_train_few_shot_CALF_Glucose_ftS_sl144_ll72_pl18_dm768_nh12_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_gpt4_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\titers: 100, epoch: 1 | loss: 26.2123642\n","\tspeed: 0.0957s/iter; left time: 3017.4226s\n","\titers: 200, epoch: 1 | loss: 24.9964809\n","\tspeed: 0.0299s/iter; left time: 938.5770s\n","\titers: 300, epoch: 1 | loss: 36.0130806\n","\tspeed: 0.0303s/iter; left time: 948.3203s\n","\titers: 400, epoch: 1 | loss: 34.4972229\n","\tspeed: 0.0296s/iter; left time: 923.3293s\n","\titers: 500, epoch: 1 | loss: 18.4930267\n","\tspeed: 0.0301s/iter; left time: 936.1302s\n","\titers: 600, epoch: 1 | loss: 22.7517700\n","\tspeed: 0.0311s/iter; left time: 963.7271s\n","\titers: 700, epoch: 1 | loss: 40.8291245\n","\tspeed: 0.0295s/iter; left time: 912.8820s\n","\titers: 800, epoch: 1 | loss: 28.2260227\n","\tspeed: 0.0294s/iter; left time: 904.8104s\n","\titers: 900, epoch: 1 | loss: 23.6846142\n","\tspeed: 0.0302s/iter; left time: 926.6993s\n","\titers: 1000, epoch: 1 | loss: 37.0862083\n","\tspeed: 0.0323s/iter; left time: 989.7794s\n","Epoch: 1 cost time: 33.57s\n","Epoch: 1 | Train Loss: 29.4909868 | Val Loss: 941.7684574\n","lr = 0.0000993845\n","Validation loss decreased (inf --> 941.768457).  Saving model ...\n","\titers: 100, epoch: 2 | loss: 16.0387268\n","\tspeed: 0.0747s/iter; left time: 2276.7073s\n","\titers: 200, epoch: 2 | loss: 22.1704464\n","\tspeed: 0.0294s/iter; left time: 892.0777s\n","\titers: 300, epoch: 2 | loss: 28.4239445\n","\tspeed: 0.0300s/iter; left time: 909.2148s\n","\titers: 400, epoch: 2 | loss: 27.3614693\n","\tspeed: 0.0307s/iter; left time: 924.7021s\n","\titers: 500, epoch: 2 | loss: 16.1198578\n","\tspeed: 0.0319s/iter; left time: 958.1726s\n","\titers: 600, epoch: 2 | loss: 22.1564922\n","\tspeed: 0.0309s/iter; left time: 926.4855s\n","\titers: 700, epoch: 2 | loss: 37.4524803\n","\tspeed: 0.0307s/iter; left time: 915.5078s\n","\titers: 800, epoch: 2 | loss: 24.9176788\n","\tspeed: 0.0292s/iter; left time: 870.1372s\n","\titers: 900, epoch: 2 | loss: 21.9516468\n","\tspeed: 0.0292s/iter; left time: 867.2015s\n","\titers: 1000, epoch: 2 | loss: 32.9407196\n","\tspeed: 0.0294s/iter; left time: 869.6984s\n","Epoch: 2 cost time: 31.81s\n","Epoch: 2 | Train Loss: 23.4010940 | Val Loss: 855.2197404\n","lr = 0.0000975531\n","Validation loss decreased (941.768457 --> 855.219740).  Saving model ...\n","\titers: 100, epoch: 3 | loss: 16.6844158\n","\tspeed: 0.0794s/iter; left time: 2336.5680s\n","\titers: 200, epoch: 3 | loss: 21.7331352\n","\tspeed: 0.0298s/iter; left time: 874.1507s\n","\titers: 300, epoch: 3 | loss: 24.6735744\n","\tspeed: 0.0298s/iter; left time: 871.6047s\n","\titers: 400, epoch: 3 | loss: 25.5089436\n","\tspeed: 0.0303s/iter; left time: 881.9659s\n","\titers: 500, epoch: 3 | loss: 14.6060381\n","\tspeed: 0.0303s/iter; left time: 878.7071s\n","\titers: 600, epoch: 3 | loss: 20.6920509\n","\tspeed: 0.0302s/iter; left time: 872.4441s\n","\titers: 700, epoch: 3 | loss: 38.1973763\n","\tspeed: 0.0301s/iter; left time: 868.4314s\n","\titers: 800, epoch: 3 | loss: 23.5304375\n","\tspeed: 0.0301s/iter; left time: 863.0947s\n","\titers: 900, epoch: 3 | loss: 20.8838615\n","\tspeed: 0.0300s/iter; left time: 859.1581s\n","\titers: 1000, epoch: 3 | loss: 33.3084373\n","\tspeed: 0.0299s/iter; left time: 853.7689s\n","Epoch: 3 cost time: 32.03s\n","Epoch: 3 | Train Loss: 22.2475230 | Val Loss: 830.3072035\n","lr = 0.0000945509\n","Validation loss decreased (855.219740 --> 830.307204).  Saving model ...\n","\titers: 100, epoch: 4 | loss: 14.5885792\n","\tspeed: 0.0787s/iter; left time: 2232.3405s\n","\titers: 200, epoch: 4 | loss: 20.7727604\n","\tspeed: 0.0295s/iter; left time: 834.1053s\n","\titers: 300, epoch: 4 | loss: 22.2332020\n","\tspeed: 0.0291s/iter; left time: 820.5972s\n","\titers: 400, epoch: 4 | loss: 25.1867256\n","\tspeed: 0.0297s/iter; left time: 834.3448s\n","\titers: 500, epoch: 4 | loss: 14.6009989\n","\tspeed: 0.0305s/iter; left time: 853.4084s\n","\titers: 600, epoch: 4 | loss: 18.5135460\n","\tspeed: 0.0306s/iter; left time: 851.0953s\n","\titers: 700, epoch: 4 | loss: 35.1810150\n","\tspeed: 0.0300s/iter; left time: 831.9171s\n","\titers: 800, epoch: 4 | loss: 23.0350266\n","\tspeed: 0.0297s/iter; left time: 821.6544s\n","\titers: 900, epoch: 4 | loss: 16.1730061\n","\tspeed: 0.0299s/iter; left time: 823.9470s\n","\titers: 1000, epoch: 4 | loss: 32.1484375\n","\tspeed: 0.0297s/iter; left time: 815.5956s\n","Epoch: 4 cost time: 31.59s\n","Epoch: 4 | Train Loss: 21.2579581 | Val Loss: 826.2328515\n","lr = 0.0000904518\n","Validation loss decreased (830.307204 --> 826.232852).  Saving model ...\n","\titers: 100, epoch: 5 | loss: 14.9506245\n","\tspeed: 0.0792s/iter; left time: 2163.2899s\n","\titers: 200, epoch: 5 | loss: 19.4147511\n","\tspeed: 0.0320s/iter; left time: 869.2740s\n","\titers: 300, epoch: 5 | loss: 22.4237804\n","\tspeed: 0.0346s/iter; left time: 937.0944s\n","\titers: 400, epoch: 5 | loss: 22.5645275\n","\tspeed: 0.0327s/iter; left time: 883.7290s\n","\titers: 500, epoch: 5 | loss: 12.7051678\n","\tspeed: 0.0298s/iter; left time: 800.8975s\n","\titers: 600, epoch: 5 | loss: 19.7971973\n","\tspeed: 0.0295s/iter; left time: 791.5854s\n","\titers: 700, epoch: 5 | loss: 34.9112320\n","\tspeed: 0.0294s/iter; left time: 786.3890s\n","\titers: 800, epoch: 5 | loss: 22.0304623\n","\tspeed: 0.0293s/iter; left time: 780.0092s\n","\titers: 900, epoch: 5 | loss: 16.4585228\n","\tspeed: 0.0299s/iter; left time: 793.4612s\n","\titers: 1000, epoch: 5 | loss: 30.1993103\n","\tspeed: 0.0294s/iter; left time: 775.7219s\n","Epoch: 5 cost time: 32.64s\n","Epoch: 5 | Train Loss: 20.5187328 | Val Loss: 815.1050846\n","lr = 0.0000853568\n","Validation loss decreased (826.232852 --> 815.105085).  Saving model ...\n","\titers: 100, epoch: 6 | loss: 14.6216230\n","\tspeed: 0.0788s/iter; left time: 2068.1762s\n","\titers: 200, epoch: 6 | loss: 19.9162083\n","\tspeed: 0.0299s/iter; left time: 782.9491s\n","\titers: 300, epoch: 6 | loss: 21.3796272\n","\tspeed: 0.0298s/iter; left time: 775.5313s\n","\titers: 400, epoch: 6 | loss: 23.1975117\n","\tspeed: 0.0294s/iter; left time: 762.1770s\n","\titers: 500, epoch: 6 | loss: 13.2272749\n","\tspeed: 0.0300s/iter; left time: 776.0382s\n","\titers: 600, epoch: 6 | loss: 18.5761089\n","\tspeed: 0.0305s/iter; left time: 784.3474s\n","\titers: 700, epoch: 6 | loss: 32.9728279\n","\tspeed: 0.0292s/iter; left time: 749.9444s\n","\titers: 800, epoch: 6 | loss: 22.8114414\n","\tspeed: 0.0293s/iter; left time: 747.7394s\n","\titers: 900, epoch: 6 | loss: 16.4435921\n","\tspeed: 0.0295s/iter; left time: 750.0757s\n","\titers: 1000, epoch: 6 | loss: 26.8688850\n","\tspeed: 0.0301s/iter; left time: 763.8069s\n","Epoch: 6 cost time: 31.65s\n","Epoch: 6 | Train Loss: 20.0302098 | Val Loss: 884.8161845\n","lr = 0.0000793913\n","EarlyStopping counter: 1 out of 8\n","\titers: 100, epoch: 7 | loss: 13.9463577\n","\tspeed: 0.0630s/iter; left time: 1587.1324s\n","\titers: 200, epoch: 7 | loss: 19.4891472\n","\tspeed: 0.0295s/iter; left time: 740.9040s\n","\titers: 300, epoch: 7 | loss: 23.1106606\n","\tspeed: 0.0301s/iter; left time: 751.9603s\n","\titers: 400, epoch: 7 | loss: 21.8517036\n","\tspeed: 0.0293s/iter; left time: 730.0476s\n","\titers: 500, epoch: 7 | loss: 12.0380335\n","\tspeed: 0.0295s/iter; left time: 730.5303s\n","\titers: 600, epoch: 7 | loss: 17.3791256\n","\tspeed: 0.0293s/iter; left time: 724.2678s\n","\titers: 700, epoch: 7 | loss: 32.9800301\n","\tspeed: 0.0301s/iter; left time: 740.7773s\n","\titers: 800, epoch: 7 | loss: 21.9659462\n","\tspeed: 0.0294s/iter; left time: 720.3926s\n","\titers: 900, epoch: 7 | loss: 15.2817059\n","\tspeed: 0.0294s/iter; left time: 717.7047s\n","\titers: 1000, epoch: 7 | loss: 26.7180195\n","\tspeed: 0.0292s/iter; left time: 710.1019s\n","Epoch: 7 cost time: 31.24s\n","Epoch: 7 | Train Loss: 19.5686807 | Val Loss: 829.5402786\n","lr = 0.0000727023\n","EarlyStopping counter: 2 out of 8\n","\titers: 100, epoch: 8 | loss: 16.7919407\n","\tspeed: 0.0629s/iter; left time: 1517.6312s\n","\titers: 200, epoch: 8 | loss: 19.3418083\n","\tspeed: 0.0294s/iter; left time: 706.3658s\n","\titers: 300, epoch: 8 | loss: 24.4999390\n","\tspeed: 0.0297s/iter; left time: 712.0815s\n","\titers: 400, epoch: 8 | loss: 21.8858604\n","\tspeed: 0.0304s/iter; left time: 724.7448s\n","\titers: 500, epoch: 8 | loss: 12.7206421\n","\tspeed: 0.0298s/iter; left time: 707.7952s\n","\titers: 600, epoch: 8 | loss: 17.4797897\n","\tspeed: 0.0297s/iter; left time: 703.1063s\n","\titers: 700, epoch: 8 | loss: 34.7722054\n","\tspeed: 0.0300s/iter; left time: 706.2021s\n","\titers: 800, epoch: 8 | loss: 21.6662178\n","\tspeed: 0.0305s/iter; left time: 715.1967s\n","\titers: 900, epoch: 8 | loss: 15.7915106\n","\tspeed: 0.0294s/iter; left time: 687.3933s\n","\titers: 1000, epoch: 8 | loss: 46.0118179\n","\tspeed: 0.0297s/iter; left time: 689.8362s\n","Epoch: 8 cost time: 31.54s\n","Epoch: 8 | Train Loss: 20.5963927 | Val Loss: 782.3954532\n","lr = 0.0000654543\n","Validation loss decreased (815.105085 --> 782.395453).  Saving model ...\n","\titers: 100, epoch: 9 | loss: 14.0790281\n","\tspeed: 0.0787s/iter; left time: 1817.0849s\n","\titers: 200, epoch: 9 | loss: 19.1170425\n","\tspeed: 0.0291s/iter; left time: 668.8816s\n","\titers: 300, epoch: 9 | loss: 20.4766788\n","\tspeed: 0.0291s/iter; left time: 667.1458s\n","\titers: 400, epoch: 9 | loss: 22.7224464\n","\tspeed: 0.0296s/iter; left time: 674.5751s\n","\titers: 500, epoch: 9 | loss: 11.0973434\n","\tspeed: 0.0306s/iter; left time: 693.8578s\n","\titers: 600, epoch: 9 | loss: 17.7124233\n","\tspeed: 0.0294s/iter; left time: 664.9764s\n","\titers: 700, epoch: 9 | loss: 31.8954563\n","\tspeed: 0.0291s/iter; left time: 654.7803s\n","\titers: 800, epoch: 9 | loss: 20.0871334\n","\tspeed: 0.0292s/iter; left time: 653.9892s\n","\titers: 900, epoch: 9 | loss: 14.9906406\n","\tspeed: 0.0302s/iter; left time: 672.3565s\n","\titers: 1000, epoch: 9 | loss: 28.9038963\n","\tspeed: 0.0295s/iter; left time: 655.4944s\n","Epoch: 9 cost time: 31.51s\n","Epoch: 9 | Train Loss: 19.1542894 | Val Loss: 744.1412298\n","lr = 0.0000578259\n","Validation loss decreased (782.395453 --> 744.141230).  Saving model ...\n","\titers: 100, epoch: 10 | loss: 14.5384712\n","\tspeed: 0.0775s/iter; left time: 1708.7529s\n","\titers: 200, epoch: 10 | loss: 19.2929630\n","\tspeed: 0.0295s/iter; left time: 647.9263s\n","\titers: 300, epoch: 10 | loss: 19.1990452\n","\tspeed: 0.0290s/iter; left time: 634.0947s\n","\titers: 400, epoch: 10 | loss: 25.4810829\n","\tspeed: 0.0293s/iter; left time: 636.6767s\n","\titers: 500, epoch: 10 | loss: 11.1853304\n","\tspeed: 0.0298s/iter; left time: 645.6778s\n","\titers: 600, epoch: 10 | loss: 15.8155451\n","\tspeed: 0.0299s/iter; left time: 643.0355s\n","\titers: 700, epoch: 10 | loss: 33.4511299\n","\tspeed: 0.0292s/iter; left time: 625.0648s\n","\titers: 800, epoch: 10 | loss: 19.0506229\n","\tspeed: 0.0292s/iter; left time: 623.9673s\n","\titers: 900, epoch: 10 | loss: 14.4552698\n","\tspeed: 0.0300s/iter; left time: 636.1467s\n","\titers: 1000, epoch: 10 | loss: 25.7478809\n","\tspeed: 0.0305s/iter; left time: 644.7831s\n","Epoch: 10 cost time: 31.55s\n","Epoch: 10 | Train Loss: 18.7237118 | Val Loss: 750.6016299\n","lr = 0.0000500050\n","EarlyStopping counter: 1 out of 8\n","\titers: 100, epoch: 11 | loss: 14.5188751\n","\tspeed: 0.0627s/iter; left time: 1315.1775s\n","\titers: 200, epoch: 11 | loss: 20.0151901\n","\tspeed: 0.0298s/iter; left time: 622.6097s\n","\titers: 300, epoch: 11 | loss: 20.4834881\n","\tspeed: 0.0298s/iter; left time: 619.5833s\n","\titers: 400, epoch: 11 | loss: 21.6155682\n","\tspeed: 0.0292s/iter; left time: 602.9576s\n","\titers: 500, epoch: 11 | loss: 10.7181063\n","\tspeed: 0.0294s/iter; left time: 605.5307s\n","\titers: 600, epoch: 11 | loss: 16.3156281\n","\tspeed: 0.0296s/iter; left time: 606.1154s\n","\titers: 700, epoch: 11 | loss: 32.3724709\n","\tspeed: 0.0300s/iter; left time: 610.8547s\n","\titers: 800, epoch: 11 | loss: 20.3997574\n","\tspeed: 0.0294s/iter; left time: 595.2485s\n","\titers: 900, epoch: 11 | loss: 15.1453171\n","\tspeed: 0.0297s/iter; left time: 599.6772s\n","\titers: 1000, epoch: 11 | loss: 23.8553658\n","\tspeed: 0.0295s/iter; left time: 593.1174s\n","Epoch: 11 cost time: 31.35s\n","Epoch: 11 | Train Loss: 18.2572436 | Val Loss: 750.1330726\n","lr = 0.0000421841\n","EarlyStopping counter: 2 out of 8\n","\titers: 100, epoch: 12 | loss: 14.3964090\n","\tspeed: 0.0634s/iter; left time: 1264.2281s\n","\titers: 200, epoch: 12 | loss: 19.5214672\n","\tspeed: 0.0297s/iter; left time: 588.9213s\n","\titers: 300, epoch: 12 | loss: 20.6922665\n","\tspeed: 0.0297s/iter; left time: 585.6988s\n","\titers: 400, epoch: 12 | loss: 20.9988632\n","\tspeed: 0.0300s/iter; left time: 588.4186s\n","\titers: 500, epoch: 12 | loss: 10.4092665\n","\tspeed: 0.0293s/iter; left time: 571.2845s\n","\titers: 600, epoch: 12 | loss: 15.9428644\n","\tspeed: 0.0294s/iter; left time: 571.5842s\n","\titers: 700, epoch: 12 | loss: 32.2168770\n","\tspeed: 0.0293s/iter; left time: 566.8444s\n","\titers: 800, epoch: 12 | loss: 19.4755764\n","\tspeed: 0.0306s/iter; left time: 588.3016s\n","\titers: 900, epoch: 12 | loss: 14.5840406\n","\tspeed: 0.0298s/iter; left time: 569.1370s\n","\titers: 1000, epoch: 12 | loss: 23.1161766\n","\tspeed: 0.0296s/iter; left time: 563.7984s\n","Epoch: 12 cost time: 31.38s\n","Epoch: 12 | Train Loss: 17.8705977 | Val Loss: 740.2646165\n","lr = 0.0000345557\n","Validation loss decreased (744.141230 --> 740.264617).  Saving model ...\n","\titers: 100, epoch: 13 | loss: 13.3083048\n","\tspeed: 0.0796s/iter; left time: 1502.2639s\n","\titers: 200, epoch: 13 | loss: 19.5089741\n","\tspeed: 0.0300s/iter; left time: 563.1338s\n","\titers: 300, epoch: 13 | loss: 20.2700996\n","\tspeed: 0.0299s/iter; left time: 558.7559s\n","\titers: 400, epoch: 13 | loss: 22.5151787\n","\tspeed: 0.0301s/iter; left time: 559.0010s\n","\titers: 500, epoch: 13 | loss: 10.5618391\n","\tspeed: 0.0307s/iter; left time: 567.0057s\n","\titers: 600, epoch: 13 | loss: 17.4044437\n","\tspeed: 0.0297s/iter; left time: 545.3363s\n","\titers: 700, epoch: 13 | loss: 33.1680679\n","\tspeed: 0.0296s/iter; left time: 540.8432s\n","\titers: 800, epoch: 13 | loss: 19.9274311\n","\tspeed: 0.0301s/iter; left time: 546.1107s\n","\titers: 900, epoch: 13 | loss: 14.6524143\n","\tspeed: 0.0300s/iter; left time: 542.8755s\n","\titers: 1000, epoch: 13 | loss: 23.1259861\n","\tspeed: 0.0293s/iter; left time: 526.8514s\n","Epoch: 13 cost time: 31.90s\n","Epoch: 13 | Train Loss: 17.7570391 | Val Loss: 737.2913472\n","lr = 0.0000273077\n","Validation loss decreased (740.264617 --> 737.291347).  Saving model ...\n","\titers: 100, epoch: 14 | loss: 13.7977524\n","\tspeed: 0.0780s/iter; left time: 1389.2822s\n","\titers: 200, epoch: 14 | loss: 19.3260918\n","\tspeed: 0.0297s/iter; left time: 526.7996s\n","\titers: 300, epoch: 14 | loss: 28.3483696\n","\tspeed: 0.0297s/iter; left time: 522.8037s\n","\titers: 400, epoch: 14 | loss: 23.6945248\n","\tspeed: 0.0306s/iter; left time: 535.5043s\n","\titers: 500, epoch: 14 | loss: 9.5459785\n","\tspeed: 0.0322s/iter; left time: 560.6386s\n","\titers: 600, epoch: 14 | loss: 16.7411499\n","\tspeed: 0.0298s/iter; left time: 515.8517s\n","\titers: 700, epoch: 14 | loss: 30.7699852\n","\tspeed: 0.0292s/iter; left time: 503.1921s\n","\titers: 800, epoch: 14 | loss: 19.5357857\n","\tspeed: 0.0293s/iter; left time: 501.7123s\n","\titers: 900, epoch: 14 | loss: 13.8185568\n","\tspeed: 0.0305s/iter; left time: 518.5883s\n","\titers: 1000, epoch: 14 | loss: 21.1232357\n","\tspeed: 0.0293s/iter; left time: 495.1206s\n","Epoch: 14 cost time: 31.96s\n","Epoch: 14 | Train Loss: 17.5494974 | Val Loss: 730.4874216\n","lr = 0.0000206187\n","Validation loss decreased (737.291347 --> 730.487422).  Saving model ...\n","\titers: 100, epoch: 15 | loss: 13.5906582\n","\tspeed: 0.0779s/iter; left time: 1305.2037s\n","\titers: 200, epoch: 15 | loss: 18.8463631\n","\tspeed: 0.0307s/iter; left time: 512.4372s\n","\titers: 300, epoch: 15 | loss: 21.3328171\n","\tspeed: 0.0296s/iter; left time: 489.7507s\n","\titers: 400, epoch: 15 | loss: 21.5597343\n","\tspeed: 0.0295s/iter; left time: 484.9845s\n","\titers: 500, epoch: 15 | loss: 9.0467386\n","\tspeed: 0.0298s/iter; left time: 487.3704s\n","\titers: 600, epoch: 15 | loss: 15.6322803\n","\tspeed: 0.0299s/iter; left time: 487.0308s\n","\titers: 700, epoch: 15 | loss: 30.7290421\n","\tspeed: 0.0293s/iter; left time: 473.8738s\n","\titers: 800, epoch: 15 | loss: 18.9999714\n","\tspeed: 0.0297s/iter; left time: 477.0268s\n","\titers: 900, epoch: 15 | loss: 14.6939240\n","\tspeed: 0.0295s/iter; left time: 471.4361s\n","\titers: 1000, epoch: 15 | loss: 20.2840538\n","\tspeed: 0.0297s/iter; left time: 471.2536s\n","Epoch: 15 cost time: 31.69s\n","Epoch: 15 | Train Loss: 17.1755866 | Val Loss: 733.5754765\n","lr = 0.0000146532\n","EarlyStopping counter: 1 out of 8\n","\titers: 100, epoch: 16 | loss: 13.0056047\n","\tspeed: 0.0630s/iter; left time: 989.8594s\n","\titers: 200, epoch: 16 | loss: 19.3883705\n","\tspeed: 0.0299s/iter; left time: 466.4767s\n","\titers: 300, epoch: 16 | loss: 21.1354122\n","\tspeed: 0.0298s/iter; left time: 462.1630s\n","\titers: 400, epoch: 16 | loss: 21.9745445\n","\tspeed: 0.0293s/iter; left time: 452.1495s\n","\titers: 500, epoch: 16 | loss: 10.0124502\n","\tspeed: 0.0293s/iter; left time: 449.0760s\n","\titers: 600, epoch: 16 | loss: 16.6867809\n","\tspeed: 0.0291s/iter; left time: 442.9710s\n","\titers: 700, epoch: 16 | loss: 31.9681854\n","\tspeed: 0.0296s/iter; left time: 447.5518s\n","\titers: 800, epoch: 16 | loss: 18.9261341\n","\tspeed: 0.0291s/iter; left time: 437.5613s\n","\titers: 900, epoch: 16 | loss: 15.1284437\n","\tspeed: 0.0294s/iter; left time: 438.5436s\n","\titers: 1000, epoch: 16 | loss: 20.1530132\n","\tspeed: 0.0292s/iter; left time: 432.0322s\n","Epoch: 16 cost time: 31.19s\n","Epoch: 16 | Train Loss: 17.3940182 | Val Loss: 752.3842437\n","lr = 0.0000095582\n","EarlyStopping counter: 2 out of 8\n","\titers: 100, epoch: 17 | loss: 14.0262604\n","\tspeed: 0.0629s/iter; left time: 922.6159s\n","\titers: 200, epoch: 17 | loss: 19.3378277\n","\tspeed: 0.0298s/iter; left time: 433.6984s\n","\titers: 300, epoch: 17 | loss: 20.0724392\n","\tspeed: 0.0297s/iter; left time: 429.3065s\n","\titers: 400, epoch: 17 | loss: 22.5855236\n","\tspeed: 0.0301s/iter; left time: 432.6872s\n","\titers: 500, epoch: 17 | loss: 10.0373411\n","\tspeed: 0.0297s/iter; left time: 423.5635s\n","\titers: 600, epoch: 17 | loss: 15.5194263\n","\tspeed: 0.0294s/iter; left time: 416.5878s\n","\titers: 700, epoch: 17 | loss: 29.2213879\n","\tspeed: 0.0295s/iter; left time: 414.5182s\n","\titers: 800, epoch: 17 | loss: 17.9308643\n","\tspeed: 0.0301s/iter; left time: 420.0846s\n","\titers: 900, epoch: 17 | loss: 15.0818806\n","\tspeed: 0.0303s/iter; left time: 419.9680s\n","\titers: 1000, epoch: 17 | loss: 19.7446384\n","\tspeed: 0.0298s/iter; left time: 410.6163s\n","Epoch: 17 cost time: 31.50s\n","Epoch: 17 | Train Loss: 16.8795033 | Val Loss: 709.0266276\n","lr = 0.0000054591\n","Validation loss decreased (730.487422 --> 709.026628).  Saving model ...\n","\titers: 100, epoch: 18 | loss: 13.2151756\n","\tspeed: 0.0792s/iter; left time: 1076.8155s\n","\titers: 200, epoch: 18 | loss: 19.3303738\n","\tspeed: 0.0292s/iter; left time: 393.8823s\n","\titers: 300, epoch: 18 | loss: 20.5241508\n","\tspeed: 0.0295s/iter; left time: 395.4472s\n","\titers: 400, epoch: 18 | loss: 20.7803173\n","\tspeed: 0.0300s/iter; left time: 399.0158s\n","\titers: 500, epoch: 18 | loss: 11.0872574\n","\tspeed: 0.0299s/iter; left time: 394.2349s\n","\titers: 600, epoch: 18 | loss: 16.4118061\n","\tspeed: 0.0295s/iter; left time: 387.0297s\n","\titers: 700, epoch: 18 | loss: 30.3666363\n","\tspeed: 0.0297s/iter; left time: 385.7691s\n","\titers: 800, epoch: 18 | loss: 17.0235500\n","\tspeed: 0.0293s/iter; left time: 378.6019s\n","\titers: 900, epoch: 18 | loss: 14.9242163\n","\tspeed: 0.0306s/iter; left time: 392.3045s\n","\titers: 1000, epoch: 18 | loss: 18.7791576\n","\tspeed: 0.0298s/iter; left time: 378.9758s\n","Epoch: 18 cost time: 31.78s\n","Epoch: 18 | Train Loss: 16.5789916 | Val Loss: 707.4885290\n","lr = 0.0000024569\n","Validation loss decreased (709.026628 --> 707.488529).  Saving model ...\n","\titers: 100, epoch: 19 | loss: 14.2123013\n","\tspeed: 0.0782s/iter; left time: 981.6345s\n","\titers: 200, epoch: 19 | loss: 19.9341354\n","\tspeed: 0.0298s/iter; left time: 371.3556s\n","\titers: 300, epoch: 19 | loss: 18.6265221\n","\tspeed: 0.0292s/iter; left time: 360.4581s\n","\titers: 400, epoch: 19 | loss: 21.3987789\n","\tspeed: 0.0297s/iter; left time: 363.3976s\n","\titers: 500, epoch: 19 | loss: 9.2872524\n","\tspeed: 0.0302s/iter; left time: 366.8214s\n","\titers: 600, epoch: 19 | loss: 15.6788063\n","\tspeed: 0.0302s/iter; left time: 363.7908s\n","\titers: 700, epoch: 19 | loss: 29.2100334\n","\tspeed: 0.0296s/iter; left time: 353.2502s\n","\titers: 800, epoch: 19 | loss: 17.3969765\n","\tspeed: 0.0293s/iter; left time: 347.0826s\n","\titers: 900, epoch: 19 | loss: 15.1658840\n","\tspeed: 0.0305s/iter; left time: 358.1817s\n","\titers: 1000, epoch: 19 | loss: 19.2024174\n","\tspeed: 0.0300s/iter; left time: 349.7567s\n","Epoch: 19 cost time: 31.74s\n","Epoch: 19 | Train Loss: 16.3946818 | Val Loss: 705.1177435\n","lr = 0.0000006255\n","Validation loss decreased (707.488529 --> 705.117743).  Saving model ...\n","\titers: 100, epoch: 20 | loss: 13.4886837\n","\tspeed: 0.0781s/iter; left time: 897.6229s\n","\titers: 200, epoch: 20 | loss: 19.6419373\n","\tspeed: 0.0302s/iter; left time: 344.6291s\n","\titers: 300, epoch: 20 | loss: 19.3484917\n","\tspeed: 0.0305s/iter; left time: 344.4691s\n","\titers: 400, epoch: 20 | loss: 21.6497345\n","\tspeed: 0.0343s/iter; left time: 384.4770s\n","\titers: 500, epoch: 20 | loss: 10.0218115\n","\tspeed: 0.0303s/iter; left time: 336.4258s\n","\titers: 600, epoch: 20 | loss: 16.2981529\n","\tspeed: 0.0300s/iter; left time: 329.8068s\n","\titers: 700, epoch: 20 | loss: 28.8165989\n","\tspeed: 0.0293s/iter; left time: 318.7296s\n","\titers: 800, epoch: 20 | loss: 17.0298939\n","\tspeed: 0.0298s/iter; left time: 321.6651s\n","\titers: 900, epoch: 20 | loss: 14.9087238\n","\tspeed: 0.0293s/iter; left time: 313.0635s\n","\titers: 1000, epoch: 20 | loss: 19.0731430\n","\tspeed: 0.0308s/iter; left time: 325.7992s\n","Epoch: 20 cost time: 32.33s\n","Epoch: 20 | Train Loss: 16.6494893 | Val Loss: 747.2289166\n","lr = 0.0000000100\n","EarlyStopping counter: 1 out of 8\n","\titers: 100, epoch: 21 | loss: 13.4791899\n","\tspeed: 0.0625s/iter; left time: 652.1481s\n","\titers: 200, epoch: 21 | loss: 19.3152447\n","\tspeed: 0.0296s/iter; left time: 305.6760s\n","\titers: 300, epoch: 21 | loss: 21.3701859\n","\tspeed: 0.0300s/iter; left time: 307.3026s\n","\titers: 400, epoch: 21 | loss: 21.0039825\n","\tspeed: 0.0296s/iter; left time: 300.3882s\n","\titers: 500, epoch: 21 | loss: 8.6028185\n","\tspeed: 0.0296s/iter; left time: 297.4007s\n","\titers: 600, epoch: 21 | loss: 16.3192310\n","\tspeed: 0.0293s/iter; left time: 291.2613s\n","\titers: 700, epoch: 21 | loss: 30.6228180\n","\tspeed: 0.0299s/iter; left time: 294.6003s\n","\titers: 800, epoch: 21 | loss: 16.1653271\n","\tspeed: 0.0294s/iter; left time: 285.9410s\n","\titers: 900, epoch: 21 | loss: 14.7060871\n","\tspeed: 0.0293s/iter; left time: 282.7356s\n","\titers: 1000, epoch: 21 | loss: 19.4638462\n","\tspeed: 0.0293s/iter; left time: 279.7036s\n","Epoch: 21 cost time: 31.28s\n","Epoch: 21 | Train Loss: 16.3871911 | Val Loss: 696.3628920\n","lr = 0.0000006255\n","Validation loss decreased (705.117743 --> 696.362892).  Saving model ...\n","\titers: 100, epoch: 22 | loss: 14.0581017\n","\tspeed: 0.0791s/iter; left time: 742.2079s\n","\titers: 200, epoch: 22 | loss: 18.9128876\n","\tspeed: 0.0297s/iter; left time: 275.5441s\n","\titers: 300, epoch: 22 | loss: 20.0939407\n","\tspeed: 0.0296s/iter; left time: 272.0882s\n","\titers: 400, epoch: 22 | loss: 21.2815590\n","\tspeed: 0.0302s/iter; left time: 274.0020s\n","\titers: 500, epoch: 22 | loss: 9.1500120\n","\tspeed: 0.0294s/iter; left time: 264.5759s\n","\titers: 600, epoch: 22 | loss: 15.3490582\n","\tspeed: 0.0299s/iter; left time: 265.6442s\n","\titers: 700, epoch: 22 | loss: 29.0416756\n","\tspeed: 0.0301s/iter; left time: 264.7285s\n","\titers: 800, epoch: 22 | loss: 16.9783821\n","\tspeed: 0.0299s/iter; left time: 260.1415s\n","\titers: 900, epoch: 22 | loss: 15.7344904\n","\tspeed: 0.0301s/iter; left time: 258.2497s\n","\titers: 1000, epoch: 22 | loss: 18.5125866\n","\tspeed: 0.0298s/iter; left time: 252.5298s\n","Epoch: 22 cost time: 31.74s\n","Epoch: 22 | Train Loss: 16.2644519 | Val Loss: 692.6948712\n","lr = 0.0000024569\n","Validation loss decreased (696.362892 --> 692.694871).  Saving model ...\n","\titers: 100, epoch: 23 | loss: 13.5880127\n","\tspeed: 0.0796s/iter; left time: 663.5100s\n","\titers: 200, epoch: 23 | loss: 19.3414707\n","\tspeed: 0.0293s/iter; left time: 240.8525s\n","\titers: 300, epoch: 23 | loss: 20.0093384\n","\tspeed: 0.0294s/iter; left time: 239.1593s\n","\titers: 400, epoch: 23 | loss: 21.1884670\n","\tspeed: 0.0301s/iter; left time: 242.1498s\n","\titers: 500, epoch: 23 | loss: 9.6149788\n","\tspeed: 0.0300s/iter; left time: 237.6641s\n","\titers: 600, epoch: 23 | loss: 16.2818584\n","\tspeed: 0.0294s/iter; left time: 230.0997s\n","\titers: 700, epoch: 23 | loss: 28.7881088\n","\tspeed: 0.0295s/iter; left time: 228.3211s\n","\titers: 800, epoch: 23 | loss: 16.3046379\n","\tspeed: 0.0303s/iter; left time: 231.6448s\n","\titers: 900, epoch: 23 | loss: 15.1248989\n","\tspeed: 0.0303s/iter; left time: 227.9861s\n","\titers: 1000, epoch: 23 | loss: 17.6629658\n","\tspeed: 0.0293s/iter; left time: 217.6822s\n","Epoch: 23 cost time: 31.64s\n","Epoch: 23 | Train Loss: 16.2950510 | Val Loss: 700.1666097\n","lr = 0.0000054591\n","EarlyStopping counter: 1 out of 8\n","\titers: 100, epoch: 24 | loss: 13.4908218\n","\tspeed: 0.0625s/iter; left time: 454.8329s\n","\titers: 200, epoch: 24 | loss: 19.0392113\n","\tspeed: 0.0305s/iter; left time: 218.7095s\n","\titers: 300, epoch: 24 | loss: 19.8042507\n","\tspeed: 0.0293s/iter; left time: 207.2968s\n","\titers: 400, epoch: 24 | loss: 22.7077656\n","\tspeed: 0.0293s/iter; left time: 204.3353s\n","\titers: 500, epoch: 24 | loss: 10.6312685\n","\tspeed: 0.0295s/iter; left time: 202.6948s\n","\titers: 600, epoch: 24 | loss: 15.3408890\n","\tspeed: 0.0297s/iter; left time: 201.3691s\n","\titers: 700, epoch: 24 | loss: 31.3130131\n","\tspeed: 0.0294s/iter; left time: 196.3816s\n","\titers: 800, epoch: 24 | loss: 16.5246677\n","\tspeed: 0.0295s/iter; left time: 193.7539s\n","\titers: 900, epoch: 24 | loss: 15.0093641\n","\tspeed: 0.0294s/iter; left time: 190.4766s\n","\titers: 1000, epoch: 24 | loss: 17.8471565\n","\tspeed: 0.0295s/iter; left time: 188.2617s\n","Epoch: 24 cost time: 31.24s\n","Epoch: 24 | Train Loss: 16.8339208 | Val Loss: 693.2782983\n","lr = 0.0000095582\n","EarlyStopping counter: 2 out of 8\n","\titers: 100, epoch: 25 | loss: 13.5972462\n","\tspeed: 0.0622s/iter; left time: 386.9651s\n","\titers: 200, epoch: 25 | loss: 19.7239723\n","\tspeed: 0.0294s/iter; left time: 180.1191s\n","\titers: 300, epoch: 25 | loss: 19.6331310\n","\tspeed: 0.0297s/iter; left time: 179.0187s\n","\titers: 400, epoch: 25 | loss: 20.9081612\n","\tspeed: 0.0295s/iter; left time: 175.0521s\n","\titers: 500, epoch: 25 | loss: 9.6508131\n","\tspeed: 0.0295s/iter; left time: 171.5928s\n","\titers: 600, epoch: 25 | loss: 16.3657589\n","\tspeed: 0.0294s/iter; left time: 168.3031s\n","\titers: 700, epoch: 25 | loss: 31.2212181\n","\tspeed: 0.0299s/iter; left time: 168.3836s\n","\titers: 800, epoch: 25 | loss: 15.8672447\n","\tspeed: 0.0295s/iter; left time: 162.7671s\n","\titers: 900, epoch: 25 | loss: 14.9995356\n","\tspeed: 0.0297s/iter; left time: 160.9695s\n","\titers: 1000, epoch: 25 | loss: 18.2517414\n","\tspeed: 0.0301s/iter; left time: 160.4475s\n","Epoch: 25 cost time: 31.31s\n","Epoch: 25 | Train Loss: 16.3247147 | Val Loss: 692.8004748\n","lr = 0.0000146532\n","EarlyStopping counter: 3 out of 8\n","\titers: 100, epoch: 26 | loss: 14.0284882\n","\tspeed: 0.0622s/iter; left time: 321.4696s\n","\titers: 200, epoch: 26 | loss: 19.7378769\n","\tspeed: 0.0294s/iter; left time: 149.3100s\n","\titers: 300, epoch: 26 | loss: 21.3211174\n","\tspeed: 0.0293s/iter; left time: 145.8047s\n","\titers: 400, epoch: 26 | loss: 21.5151405\n","\tspeed: 0.0301s/iter; left time: 146.6313s\n","\titers: 500, epoch: 26 | loss: 10.2150698\n","\tspeed: 0.0297s/iter; left time: 141.8604s\n","\titers: 600, epoch: 26 | loss: 17.2608986\n","\tspeed: 0.0297s/iter; left time: 138.6967s\n","\titers: 700, epoch: 26 | loss: 28.6470470\n","\tspeed: 0.0296s/iter; left time: 135.2236s\n","\titers: 800, epoch: 26 | loss: 16.4224949\n","\tspeed: 0.0300s/iter; left time: 134.1180s\n","\titers: 900, epoch: 26 | loss: 14.7746477\n","\tspeed: 0.0298s/iter; left time: 130.1335s\n","\titers: 1000, epoch: 26 | loss: 17.7501411\n","\tspeed: 0.0296s/iter; left time: 126.5660s\n","Epoch: 26 cost time: 31.35s\n","Epoch: 26 | Train Loss: 16.4370367 | Val Loss: 704.3979554\n","lr = 0.0000206187\n","EarlyStopping counter: 4 out of 8\n","\titers: 100, epoch: 27 | loss: 14.5718994\n","\tspeed: 0.0637s/iter; left time: 262.1976s\n","\titers: 200, epoch: 27 | loss: 20.4562778\n","\tspeed: 0.0299s/iter; left time: 120.0125s\n","\titers: 300, epoch: 27 | loss: 23.7703495\n","\tspeed: 0.0297s/iter; left time: 116.1942s\n","\titers: 400, epoch: 27 | loss: 23.5553169\n","\tspeed: 0.0297s/iter; left time: 113.4591s\n","\titers: 500, epoch: 27 | loss: 8.8639278\n","\tspeed: 0.0304s/iter; left time: 112.8420s\n","\titers: 600, epoch: 27 | loss: 16.1702518\n","\tspeed: 0.0296s/iter; left time: 106.9044s\n","\titers: 700, epoch: 27 | loss: 30.1270733\n","\tspeed: 0.0293s/iter; left time: 103.1064s\n","\titers: 800, epoch: 27 | loss: 17.8731709\n","\tspeed: 0.0295s/iter; left time: 100.6782s\n","\titers: 900, epoch: 27 | loss: 15.0795050\n","\tspeed: 0.0302s/iter; left time: 100.0743s\n","\titers: 1000, epoch: 27 | loss: 19.0584507\n","\tspeed: 0.0294s/iter; left time: 94.4791s\n","Epoch: 27 cost time: 31.47s\n","Epoch: 27 | Train Loss: 17.7175298 | Val Loss: 717.7656387\n","lr = 0.0000273077\n","EarlyStopping counter: 5 out of 8\n","\titers: 100, epoch: 28 | loss: 13.9805803\n","\tspeed: 0.0623s/iter; left time: 190.8362s\n","\titers: 200, epoch: 28 | loss: 19.5177422\n","\tspeed: 0.0305s/iter; left time: 90.4741s\n","\titers: 300, epoch: 28 | loss: 20.7635994\n","\tspeed: 0.0296s/iter; left time: 84.7993s\n","\titers: 400, epoch: 28 | loss: 23.2249889\n","\tspeed: 0.0294s/iter; left time: 81.1462s\n","\titers: 500, epoch: 28 | loss: 8.9669409\n","\tspeed: 0.0294s/iter; left time: 78.2887s\n","\titers: 600, epoch: 28 | loss: 17.8237057\n","\tspeed: 0.0299s/iter; left time: 76.6267s\n","\titers: 700, epoch: 28 | loss: 29.4307976\n","\tspeed: 0.0298s/iter; left time: 73.4365s\n","\titers: 800, epoch: 28 | loss: 16.8951702\n","\tspeed: 0.0300s/iter; left time: 70.9076s\n","\titers: 900, epoch: 28 | loss: 15.5100870\n","\tspeed: 0.0299s/iter; left time: 67.7546s\n","\titers: 1000, epoch: 28 | loss: 18.8612881\n","\tspeed: 0.0298s/iter; left time: 64.5486s\n","Epoch: 28 cost time: 31.49s\n","Epoch: 28 | Train Loss: 16.3878880 | Val Loss: 718.3299061\n","lr = 0.0000345557\n","EarlyStopping counter: 6 out of 8\n","\titers: 100, epoch: 29 | loss: 13.0978165\n","\tspeed: 0.0622s/iter; left time: 125.0182s\n","\titers: 200, epoch: 29 | loss: 19.1576824\n","\tspeed: 0.0292s/iter; left time: 55.7972s\n","\titers: 300, epoch: 29 | loss: 24.9865246\n","\tspeed: 0.0298s/iter; left time: 53.8350s\n","\titers: 400, epoch: 29 | loss: 21.6346817\n","\tspeed: 0.0297s/iter; left time: 50.7671s\n","\titers: 500, epoch: 29 | loss: 9.4756203\n","\tspeed: 0.0294s/iter; left time: 47.2674s\n","\titers: 600, epoch: 29 | loss: 17.1033630\n","\tspeed: 0.0296s/iter; left time: 44.6076s\n","\titers: 700, epoch: 29 | loss: 35.7733078\n","\tspeed: 0.0297s/iter; left time: 41.8426s\n","\titers: 800, epoch: 29 | loss: 17.7907562\n","\tspeed: 0.0300s/iter; left time: 39.2170s\n","\titers: 900, epoch: 29 | loss: 13.8934746\n","\tspeed: 0.0294s/iter; left time: 35.5036s\n","\titers: 1000, epoch: 29 | loss: 17.4714832\n","\tspeed: 0.0295s/iter; left time: 32.7693s\n","Epoch: 29 cost time: 31.25s\n","Epoch: 29 | Train Loss: 16.8057258 | Val Loss: 716.2379027\n","lr = 0.0000421841\n","EarlyStopping counter: 7 out of 8\n","\titers: 100, epoch: 30 | loss: 13.7240000\n","\tspeed: 0.0633s/iter; left time: 60.4328s\n","\titers: 200, epoch: 30 | loss: 19.7239151\n","\tspeed: 0.0298s/iter; left time: 25.5156s\n","\titers: 300, epoch: 30 | loss: 21.5105286\n","\tspeed: 0.0294s/iter; left time: 22.2142s\n","\titers: 400, epoch: 30 | loss: 22.7075996\n","\tspeed: 0.0297s/iter; left time: 19.4286s\n","\titers: 500, epoch: 30 | loss: 9.1490107\n","\tspeed: 0.0304s/iter; left time: 16.8636s\n","\titers: 600, epoch: 30 | loss: 17.3402367\n","\tspeed: 0.0295s/iter; left time: 13.4182s\n","\titers: 700, epoch: 30 | loss: 32.2769508\n","\tspeed: 0.0291s/iter; left time: 10.3394s\n","\titers: 800, epoch: 30 | loss: 17.1356945\n","\tspeed: 0.0294s/iter; left time: 7.5036s\n","\titers: 900, epoch: 30 | loss: 15.8484688\n","\tspeed: 0.0302s/iter; left time: 4.6785s\n","\titers: 1000, epoch: 30 | loss: 18.8268566\n","\tspeed: 0.0296s/iter; left time: 1.6294s\n","Epoch: 30 cost time: 31.45s\n","Epoch: 30 | Train Loss: 16.4894209 | Val Loss: 735.8263019\n","lr = 0.0000500050\n","EarlyStopping counter: 8 out of 8\n","Early stopping\n"]}]},{"cell_type":"code","source":["!python run.py \\\n","  --task_name long_term_forecast \\\n","  --is_training 0 \\\n","  --model CALF \\\n","  --model_id glucose_train_few_shot \\\n","  --data Glucose \\\n","  --root_path /unused/during/test \\\n","  --test_root_path /content/drive/Shareddrives/Baiying/preprocessed_dataset/test_dataset/mixed \\\n","  --features S \\\n","  --checkpoints ./checkpoints \\\n","  --seq_len 144 \\\n","  --label_len 72 \\\n","  --pred_len 18 \\\n","  --d_model 768 \\\n","  --n_heads 12 \\\n","  --stride 1 \\\n","  --gpt_layers 4 \\\n","  --batch_size 32 \\\n","  --scale_value 1.0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMawuTY_IXQN","executionInfo":{"status":"ok","timestamp":1769540512685,"user_tz":300,"elapsed":963988,"user":{"displayName":"PI DigitalSMD","userId":"16790990030515584217"}},"outputId":"cc944481-a2d2-4042-ced6-447265748ebd","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Args in experiment:\n","\u001b[1mBasic Config\u001b[0m\n","  Task Name:          long_term_forecast  Is Training:        0                   \n","  Model ID:           glucose_train_few_shotModel:              CALF                \n","\n","\u001b[1mData Loader\u001b[0m\n","  Data:               Glucose             Root Path:          /unused/during/test \n","  Data Path:          ETTh1.csv           Features:           S                   \n","  Target:             OT                  Freq:               h                   \n","  Checkpoints:        ./checkpoints       \n","\n","\u001b[1mForecasting Task\u001b[0m\n","  Seq Len:            144                 Label Len:          72                  \n","  Pred Len:           18                  Seasonal Patterns:  Monthly             \n","  Inverse:            0                   \n","\n","\u001b[1mModel Parameters\u001b[0m\n","  Top k:              5                   Num Kernels:        6                   \n","  Enc In:             7                   Dec In:             7                   \n","  C Out:              7                   d model:            768                 \n","  n heads:            12                  e layers:           2                   \n","  d layers:           1                   d FF:               2048                \n","  Moving Avg:         25                  Factor:             1                   \n","  Distil:             1                   Dropout:            0.1                 \n","  Embed:              timeF               Activation:         gelu                \n","  Output Attention:   0                   \n","\n","\u001b[1mRun Parameters\u001b[0m\n","  Num Workers:        10                  Itr:                1                   \n","  Train Epochs:       10                  Batch Size:         32                  \n","  Patience:           3                   Learning Rate:      0.0001              \n","  Des:                test                Feature Loss:       l1                  Output Loss:        l1                  Task Loss:          l1                  \n","  Lradj:              type1               Use Amp:            0                   \n","\n","\u001b[1mGPU\u001b[0m\n","  Use GPU:            1                   GPU:                0                   \n","  Use Multi GPU:      0                   Devices:            0,1,2,3             \n","\n","\u001b[1mDe-stationary Projector Params\u001b[0m\n","  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n","\n","\u001b[1mDistill Loss Weight\u001b[0m\n","  Feature Weight:     0.01                Output Weight:      1.0                 Task Weight:        1.0                 \n","\n","Use GPU: cuda:0\n",">>>>>>>testing : long_term_forecast_glucose_train_few_shot_CALF_Glucose_ftS_sl144_ll72_pl18_dm768_nh12_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_gpt4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","loading model\n","[TEST] mse:778.9210205078125, mae:17.287137985229492\n","[TEST] Per-subject metrics saved to ./results/long_term_forecast_glucose_train_few_shot_CALF_Glucose_ftS_sl144_ll72_pl18_dm768_nh12_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_gpt4_0/per_subject_metrics\n"]}]},{"cell_type":"code","source":["!python run.py \\\n","  --task_name long_term_forecast \\\n","  --is_training 0 \\\n","  --model CALF \\\n","  --model_id glucose_train_few_shot \\\n","  --data Glucose \\\n","  --root_path /unused/during/test \\\n","  --test_root_path /content/drive/Shareddrives/Baiying/preprocessed_dataset/test_dataset/controlled_datasets/8_DiaTrend \\\n","  --features S \\\n","  --checkpoints ./checkpoints \\\n","  --seq_len 144 \\\n","  --label_len 72 \\\n","  --pred_len 18 \\\n","  --d_model 768 \\\n","  --n_heads 12 \\\n","  --stride 1 \\\n","  --gpt_layers 4 \\\n","  --batch_size 32 \\\n","  --scale_value 1.0\n"],"metadata":{"id":"GLy26IrCIXSB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769395776306,"user_tz":300,"elapsed":857884,"user":{"displayName":"PI DigitalSMD","userId":"16790990030515584217"}},"outputId":"bc690617-8bee-41a7-c498-ac3a9855cc09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Args in experiment:\n","\u001b[1mBasic Config\u001b[0m\n","  Task Name:          long_term_forecast  Is Training:        0                   \n","  Model ID:           glucose_train_few_shotModel:              CALF                \n","\n","\u001b[1mData Loader\u001b[0m\n","  Data:               Glucose             Root Path:          /unused/during/test \n","  Data Path:          ETTh1.csv           Features:           S                   \n","  Target:             OT                  Freq:               h                   \n","  Checkpoints:        ./checkpoints       \n","\n","\u001b[1mForecasting Task\u001b[0m\n","  Seq Len:            144                 Label Len:          72                  \n","  Pred Len:           18                  Seasonal Patterns:  Monthly             \n","  Inverse:            0                   \n","\n","\u001b[1mModel Parameters\u001b[0m\n","  Top k:              5                   Num Kernels:        6                   \n","  Enc In:             7                   Dec In:             7                   \n","  C Out:              7                   d model:            768                 \n","  n heads:            12                  e layers:           2                   \n","  d layers:           1                   d FF:               2048                \n","  Moving Avg:         25                  Factor:             1                   \n","  Distil:             1                   Dropout:            0.1                 \n","  Embed:              timeF               Activation:         gelu                \n","  Output Attention:   0                   \n","\n","\u001b[1mRun Parameters\u001b[0m\n","  Num Workers:        10                  Itr:                1                   \n","  Train Epochs:       10                  Batch Size:         32                  \n","  Patience:           3                   Learning Rate:      0.0001              \n","  Des:                test                Feature Loss:       l1                  Output Loss:        l1                  Task Loss:          l1                  \n","  Lradj:              type1               Use Amp:            0                   \n","\n","\u001b[1mGPU\u001b[0m\n","  Use GPU:            1                   GPU:                0                   \n","  Use Multi GPU:      0                   Devices:            0,1,2,3             \n","\n","\u001b[1mDe-stationary Projector Params\u001b[0m\n","  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n","\n","\u001b[1mDistill Loss Weight\u001b[0m\n","  Feature Weight:     0.01                Output Weight:      1.0                 Task Weight:        1.0                 \n","\n","Use GPU: cuda:0\n",">>>>>>>testing : long_term_forecast_glucose_train_few_shot_CALF_Glucose_ftS_sl144_ll72_pl18_dm768_nh12_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_gpt4_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","loading model\n","[TEST] mse:1686.9886474609375, mae:27.804006576538086\n","[TEST] Per-subject metrics saved to ./results/long_term_forecast_glucose_train_few_shot_CALF_Glucose_ftS_sl144_ll72_pl18_dm768_nh12_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_gpt4_0/per_subject_metrics\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AKEDe4HcLZ5T"},"execution_count":null,"outputs":[]}]}